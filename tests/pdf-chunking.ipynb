{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZATION METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD 1: Unstructured default tokenization\n",
    "\n",
    "# Install the packages and libmagic for automatic file type detection\n",
    "pip install \"unstructured[all-docs]\"\n",
    "pip install unstructured-client\n",
    "brew install libmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured_client import UnstructuredClient\n",
    "s = UnstructuredClient(api_key_auth=\"UXNnvEtTT7FyVI1qY1R85616zcN8eO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./gpt-4.pdf\"\n",
    "file = open(filename, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartitionParameters(chunking_strategy=None, combine_under_n_chars=None, coordinates=None, encoding=None, files=Files(content=b'', file_name='./gpt-4.pdf'), gz_uncompressed_content_type=None, hi_res_model_name=None, include_page_breaks=None, languages=None, max_characters=None, multipage_sections=None, new_after_n_chars=None, output_format=None, pdf_infer_table_structure=None, skip_infer_table_types=None, strategy='fast', xml_keep_tags=None)\n"
     ]
    }
   ],
   "source": [
    "from unstructured_client.models import shared\n",
    "\n",
    "req = shared.PartitionParameters(\n",
    "    # Note that this currently only supports a single file\n",
    "    files=shared.Files(\n",
    "        content=file.read(),\n",
    "        file_name=filename,\n",
    "    ),\n",
    "    # Other partition params\n",
    "    strategy=\"fast\", # fast, hi_res, auto. For details see https://unstructured-io.github.io/unstructured/best_practices/strategies.html\n",
    ")\n",
    "print(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'UncategorizedText', 'element_id': 'a04b820b51c760a41415c57c1eef8f08', 'text': '3 2 0 2', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '452202c3d8a420d49447943b87c30d0e', 'text': 'r a', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '27aa14beb95d26e84d7cb2b9d4dbec83', 'text': 'M 7 2', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '452202c3d8a420d49447943b87c30d0e', 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '3e16d5218a727bdf70d048a818de45a9', 'text': '] L C . s c [', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'fef8fa7a97cf378a4fe8d4292a267851', 'text': '8 0 5 2 1 8 4 / t i', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '3e16d5218a727bdf70d048a818de45a9', 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'cf20c177bd572d2c3dda56ef2274868b', 'text': 'm b u s : v i X r a', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '3e16d5218a727bdf70d048a818de45a9', 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '4b955a5b0371c42b7e0b64d31e3220b9', 'text': 'GPT-4 Technical Report', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '104d43f7b0c62895854035737110e4e8', 'text': 'OpenAI∗', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'd21b4a64a2d8656a0fdf7ab2e89a4916', 'text': 'Abstract', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '07b19feed38edc331adcd062c046a3fa', 'text': 'We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer- based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': 'd21b4a64a2d8656a0fdf7ab2e89a4916', 'filename': 'gpt-4.pdf', 'filetype': 'application/pdf'}}\n"
     ]
    }
   ],
   "source": [
    "# Default Unstructured partitioning\n",
    "\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "try:\n",
    "    res = s.general.partition(req)\n",
    "    for i in range(10):\n",
    "        print(res.elements[i])\n",
    "except SDKError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD 2: Proposition-based tokenization\n",
    "\n",
    "# Install package to read PDF\n",
    "pip install PyPDF2\n",
    "pip install transformers\n",
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"This technical report presents GPT-4, a large multimodal model.\",\n",
      "  \"GPT-4 can accept image and text inputs and produce text outputs.\",\n",
      "  \"GPT-4 is less capable than humans in many real-world scenarios.\",\n",
      "  \"GPT-4 exhibits human-level performance on various professional and academic benchmarks.\",\n",
      "  \"GPT-4 passed a simulated bar exam with a score around the top 10% of test takers.\",\n",
      "  \"GPT-4 is a Transformer-based model pre-trained to predict the next token in a document.\",\n",
      "  \"The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior.\",\n",
      "  \"A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales.\",\n",
      "  \"This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Proposition-based retrieval\n",
    "\n",
    "# Read all text from PDF\n",
    "import PyPDF2\n",
    "reader = PyPDF2.PdfReader('gpt-4.pdf')\n",
    "content = \"\"\n",
    "for i in range(len(reader.pages)):\n",
    "    content += reader.pages[i].extract_text()\n",
    "\n",
    "# Use a small portion of text for testing\n",
    "content = content[:1000]\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_name = \"chentong00/propositionizer-wiki-flan-t5-large\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "input_ids = tokenizer(content, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids.to(device), max_new_tokens=512).cpu()\n",
    "\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "try:\n",
    "    prop_list = json.loads(output_text)\n",
    "except:\n",
    "    prop_list = []\n",
    "    print(\"[ERROR] Failed to parse output text as JSON.\")\n",
    "print(json.dumps(prop_list, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
