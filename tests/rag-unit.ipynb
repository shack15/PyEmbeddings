{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/sdan/Developer/shack15/PyEmbeddings\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/sdan/miniforge3/lib/python3.10/site-packages (from pyembeddings==0.1.0) (2.31.0)\n",
      "Requirement already satisfied: transformers in /Users/sdan/miniforge3/lib/python3.10/site-packages (from pyembeddings==0.1.0) (4.25.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from requests->pyembeddings==0.1.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from requests->pyembeddings==0.1.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from requests->pyembeddings==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from requests->pyembeddings==0.1.0) (1.26.16)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (2022.10.31)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (0.13.2)\n",
      "Requirement already satisfied: filelock in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (3.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (23.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from transformers->pyembeddings==0.1.0) (6.0)\n",
      "Requirement already satisfied: fsspec in /Users/sdan/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers->pyembeddings==0.1.0) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sdan/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers->pyembeddings==0.1.0) (4.8.0)\n",
      "Building wheels for collected packages: pyembeddings\n",
      "  Building wheel for pyembeddings (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyembeddings: filename=pyembeddings-0.1.0-py3-none-any.whl size=6518 sha256=9eb3e3384a4c470d77cfce3e6178d7e7e5bf70260d979f9587601f1b630d7691\n",
      "  Stored in directory: /private/var/folders/dq/j77slcv91170y4nzv0qxxpz80000gn/T/pip-ephem-wheel-cache-5u5s5vzw/wheels/5a/d2/73/bdd11bd0676c381b55b3ef88810bd2f467bc9676c5182b3980\n",
      "Successfully built pyembeddings\n",
      "Installing collected packages: pyembeddings\n",
      "  Attempting uninstall: pyembeddings\n",
      "    Found existing installation: pyembeddings 0.1.0\n",
      "    Uninstalling pyembeddings-0.1.0:\n",
      "      Successfully uninstalled pyembeddings-0.1.0\n",
      "Successfully installed pyembeddings-0.1.0\n",
      "Name: pyembeddings\n",
      "Version: 0.1.0\n",
      "Summary: Simple and intuitive embeddings generation, storage, and retrieval.\n",
      "Home-page: https://github.com/shack15/PyEmbeddings\n",
      "Author: Anant Sinha\n",
      "Author-email: anant@shack15.com\n",
      "License: \n",
      "Location: /Users/sdan/miniforge3/lib/python3.10/site-packages\n",
      "Requires: requests, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Setup script for pyembeddings\n",
    "!pip install ../\n",
    "!pip show pyembeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG example  {'prompt_response': 'The retrieved context does not provide specific information about what is new with GPT-4.', 'results': 'page_content=\\'##t - 4 ) is shown as the dotted line ; this ﬁt accurately predicts gpt - 4 ’ s performance. the x - axis is training compute normalized so that gpt - 4 is 1. 3\\' metadata={\\'page\\': 2, \\'source\\': \\'file.pdf\\', \\'url\\': \\'file.pdf\\'}\\npage_content=\\'observed prediction gpt - 4 100p 10n 1µ 100µ 0. 01 1 compute1. 02. 03. 04. 05. 06. 0bits per wordopenai codebase next word predictionfigure 1. performance of gpt - 4 and smaller models. the metric is ﬁnal loss on a dataset derived from our internal codebase. this is a convenient, large dataset of code tokens which is not contained in the training set. we chose to look at loss because it tends to be less noisy than other measures across different amounts of training compute. a power law ﬁt to the smaller models ( excluding gpt - 4 ) is shown as the dotted line ; this ﬁt accurately predicts gpt - 4 ’ s ﬁnal loss. the x - axis is training compute normalized so that gpt - 4 is 1. observed prediction gpt - 4 1µ 10µ 100µ 0. 001 0. 01 0. 1 1 compute012345 – mean log pass ratecapability prediction on 23 coding problems figure 2. performance of gpt - 4 and smaller models. the metric is mean log pass rate on a subset of the humaneval dataset. a power law ﬁt to the smaller models ( excluding gp\\' metadata={\\'page\\': 2, \\'source\\': \\'file.pdf\\', \\'url\\': \\'file.pdf\\'}\\npage_content=\\'from experience. care should be taken when using the outputs of gpt - 4, particularly in contexts where reliability is important. gpt - 4 ’ s capabilities and limitations create signiﬁcant and novel safety challenges, and we believe careful study of these challenges is an important area of research given the potential societal impact. this report includes an extensive system card ( after the appendix ) describing some of the risks we foresee around bias, disinformation, over - reliance, privacy, cybersecurity, proliferation, and more. it also describes interventions we made to mitigate potential harms from the deployment of gpt - 4, including adversarial testing with domain experts, and a model - assisted safety pipeline. 2 scope and limitations of this technical report this report focuses on the capabilities, limitations, and safety properties of gpt - 4. gpt - 4 is a transformer - style model [ 39 ] pre - trained to predict the next token in a document, using both publicly available data ( such as internet data ) and data licensed from third - party providers. the model was then ﬁne - tuned using reinforcement learning from human feedback ( rlhf ) [ 40 ]. given both the competitive landscape and the safety implications of large -\\' metadata={\\'page\\': 1, \\'source\\': \\'file.pdf\\', \\'url\\': \\'file.pdf\\'}\\npage_content=\\'variants of mmlu, gpt - 4 surpasses the english - language state - of - the - art in 24 of 26 languages considered. we discuss these model capability results, as well as model safety improvements and results, in more detail in later sections. this report also discusses a key challenge of the project, developing deep learning infrastructure and optimization methods that behave predictably across a wide range of scales. this allowed us to make predictions about the expected performance of gpt - 4 ( based on small runs trained in similar ways ) that were tested against the ﬁnal run to increase conﬁdence in our training. despite its capabilities, gpt - 4 has similar limitations to earlier gpt models [ 1, 37, 38 ] : it is not fully reliable ( e. g. can suffer from “ hallucinations ” ), has a limited context window, and does not learn ∗please cite this work as “ openai ( 2023 ) \". full authorship contribution statements appear at the end of the document. correspondence regarding this technical report can be sent to gpt4 - report @ openai. comarxiv : submit / 4812508 [ cs. cl ] 27 mar 2023\\' metadata={\\'page\\': 0, \\'source\\': \\'file.pdf\\', \\'url\\': \\'file.pdf\\'}'}\n"
     ]
    }
   ],
   "source": [
    "import pyembeddings\n",
    "\n",
    "pyembeddings.init('f257bbe3-bbc3-4885-90a1-3bd48e6ec591')\n",
    "\n",
    "db = pyembeddings.Database()\n",
    "collection = db.create_collection('gpt4_paper', 'MiniLM')\n",
    "\n",
    "gen = pyembeddings.Generator()\n",
    "gen.set_model(\"MiniLM\")\n",
    "\n",
    "# Embed the paper into the collection\n",
    "pdf_embeddings = gen.embed(\"./gpt-4.pdf\")\n",
    "\n",
    "# Add the embeddings to the collection\n",
    "collection.add(pdf_embeddings)\n",
    "\n",
    "# RAG example\n",
    "print(\"RAG example \",collection.retrieval_augmented_generation(query=\"What is new with GPT-4?\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
